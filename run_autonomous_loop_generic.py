#!/usr/bin/env python3
"""
Generic Autonomous Loop Runner for JupyterHub

Reads candidates from a JSON file (generated by frontend) and runs the experiment.
This way you don't need a new script for each loop iteration.

Usage:
    python run_autonomous_loop_generic.py --candidates candidates.json

The JSON file should have this format:
[
  {
    "compound": "CCCP",
    "cell_line": "A549",
    "timepoint_h": 12.0,
    "wells": 12,
    "priority": "Primary"
  },
  ...
]
"""
import argparse
import json
import sys
sys.path.insert(0, '.')
from standalone_cell_thalamus import run_parallel_simulation, WellAssignment
import standalone_cell_thalamus as standalone

def load_candidates(json_path):
    """Load candidates from JSON file"""
    with open(json_path, 'r') as f:
        return json.load(f)

def run_autonomous_loop(candidates_json_path, workers=8):
    """Run autonomous loop with candidates from JSON"""

    # Load candidates
    candidates = load_candidates(candidates_json_path)

    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          AUTONOMOUS LOOP EXPERIMENT FROM JSON                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Loaded {len(candidates)} candidates from: {candidates_json_path}

Candidates:
""")

    total_experimental_wells = 0
    for i, candidate in enumerate(candidates, 1):
        compound = candidate['compound']
        cell_line = candidate.get('cell_line', 'A549')
        timepoint = candidate.get('timepoint_h', 12.0)
        wells = candidate.get('wells', 12)
        priority = candidate.get('priority', 'Probe')
        total_experimental_wells += wells

        print(f"  {i:2d}. {compound:20s} @ {cell_line:6s} @ {timepoint:4.0f}h ({wells:2d} wells) [{priority}]")

    # Calculate control wells (12 DMSO + 4 sentinels per plate, 2 plates)
    # Matches original design pattern: 8 DMSO + 4 tBHQ + 4 tunicamycin per plate
    num_plates = 2
    dmso_per_plate = 12
    sentinels_per_plate = 4  # 2 tBHQ + 2 tunicamycin
    control_wells = num_plates * (dmso_per_plate + sentinels_per_plate)
    total_wells = total_experimental_wells + control_wells

    print(f"""
Experimental design:
- {len(candidates)} compound+cell+timepoint combinations
- {total_experimental_wells} experimental wells (allocated by priority)
- {control_wells} control wells ({dmso_per_plate} DMSO + {sentinels_per_plate} sentinels per plate)
  * 24 DMSO controls (vehicle)
  * 4 tBHQ sentinels (oxidative stress QC)
  * 4 tunicamycin sentinels (ER stress QC)
- Total: {total_wells} wells (~{total_wells / 96:.1f} plates)

Running with {workers} workers (~10-15 minutes)...
""")

    # Patch generate_design to use autonomous loop settings
    original_generate = standalone.generate_design

    def custom_generate(candidates_list, mode):
        """Custom design generator that respects well allocations"""
        dose_levels = [0.0, 0.1, 1.0, 10.0]  # 4 doses
        days = [1]
        operators = ['Operator_A']

        design = []
        well_idx = 0
        plate_id = f"AutoLoop_Day1_OpA"

        # Process each candidate with its specific allocation
        for candidate in candidates_list:
            compound = candidate['compound']
            cell_line = candidate['cell_line']
            timepoint = candidate['timepoint_h']
            allocated_wells = candidate['wells']

            # Get compound parameters
            compound_params = standalone.COMPOUND_PARAMS.get(compound, {'ec50_uM': 10.0})
            ec50 = compound_params['ec50_uM']

            # Distribute allocated wells across 4 doses
            # Each dose gets allocated_wells/4 replicates
            replicates_per_dose = allocated_wells // 4
            extra_wells = allocated_wells % 4

            for dose_idx, dose_frac in enumerate(dose_levels):
                dose_uM = dose_frac * ec50 if dose_frac > 0 else 0.0

                # Number of replicates for this dose (distribute extras to first doses)
                num_reps = replicates_per_dose + (1 if dose_idx < extra_wells else 0)

                for rep in range(num_reps):
                    design.append(WellAssignment(
                        well_id=f"W{well_idx:04d}",
                        cell_line=cell_line,
                        compound=compound,
                        dose_uM=dose_uM,
                        timepoint_h=timepoint,
                        plate_id=plate_id,
                        day=1,
                        operator='Operator_A',
                        is_sentinel=False
                    ))
                    well_idx += 1

        # Add controls matching original design pattern
        # 2 plates Ã— (12 DMSO + 2 tBHQ + 2 tunicamycin) = 32 control wells

        # Get unique cell_line Ã— timepoint combinations from candidates
        from collections import defaultdict
        combinations = set((c['cell_line'], c['timepoint_h']) for c in candidates_list)
        combinations_list = sorted(list(combinations))

        # Distribute 24 DMSO across combinations (12 per plate, ~6 per combination for 2 plates Ã— 2 combinations)
        total_dmso = 24
        dmso_per_combo = total_dmso // len(combinations_list)
        extra_dmso = total_dmso % len(combinations_list)

        for combo_idx, (cell_line, timepoint) in enumerate(combinations_list):
            num_dmso = dmso_per_combo + (1 if combo_idx < extra_dmso else 0)
            for _ in range(num_dmso):
                design.append(WellAssignment(
                    well_id=f"W{well_idx:04d}",
                    cell_line=cell_line,
                    compound='DMSO',
                    dose_uM=0.0,
                    timepoint_h=timepoint,
                    plate_id=plate_id,
                    day=1,
                    operator='Operator_A',
                    is_sentinel=True
                ))
                well_idx += 1

        # Add 4 tBHQ sentinels (distributed across combinations)
        total_tbhq = 4
        tbhq_per_combo = total_tbhq // len(combinations_list)
        extra_tbhq = total_tbhq % len(combinations_list)

        for combo_idx, (cell_line, timepoint) in enumerate(combinations_list):
            num_tbhq = tbhq_per_combo + (1 if combo_idx < extra_tbhq else 0)
            # Get tBHQ EC50 for this cell line
            tbhq_params = standalone.COMPOUND_PARAMS.get('tBHQ', {'ec50_uM': 30.0})
            tbhq_dose = 1.0 * tbhq_params['ec50_uM']  # Use 1Ã— EC50

            for _ in range(num_tbhq):
                design.append(WellAssignment(
                    well_id=f"W{well_idx:04d}",
                    cell_line=cell_line,
                    compound='tBHQ',
                    dose_uM=tbhq_dose,
                    timepoint_h=timepoint,
                    plate_id=plate_id,
                    day=1,
                    operator='Operator_A',
                    is_sentinel=True
                ))
                well_idx += 1

        # Add 4 tunicamycin sentinels (distributed across combinations)
        total_tunicamycin = 4
        tunicamycin_per_combo = total_tunicamycin // len(combinations_list)
        extra_tunicamycin = total_tunicamycin % len(combinations_list)

        for combo_idx, (cell_line, timepoint) in enumerate(combinations_list):
            num_tunicamycin = tunicamycin_per_combo + (1 if combo_idx < extra_tunicamycin else 0)
            # Get tunicamycin EC50 for this cell line
            tunicamycin_params = standalone.COMPOUND_PARAMS.get('tunicamycin', {'ec50_uM': 2.0})
            tunicamycin_dose = 1.0 * tunicamycin_params['ec50_uM']  # Use 1Ã— EC50

            for _ in range(num_tunicamycin):
                design.append(WellAssignment(
                    well_id=f"W{well_idx:04d}",
                    cell_line=cell_line,
                    compound='tunicamycin',
                    dose_uM=tunicamycin_dose,
                    timepoint_h=timepoint,
                    plate_id=plate_id,
                    day=1,
                    operator='Operator_A',
                    is_sentinel=True
                ))
                well_idx += 1

        return design

    # Monkey-patch - wrap custom_generate to pass candidates through
    def patched_generate(cell_lines_arg, compounds_arg, mode):
        """Wrapper that calls custom_generate with candidates list"""
        return custom_generate(candidates, mode)

    standalone.generate_design = patched_generate

    # Extract unique cell lines and compounds for run_parallel_simulation
    cell_lines_set = set(c.get('cell_line', 'A549') for c in candidates)
    compounds_set = set(c['compound'] for c in candidates)

    try:
        # Run simulation
        design_id = run_parallel_simulation(
            cell_lines=list(cell_lines_set),
            compounds=list(compounds_set),
            mode='custom',
            workers=workers,
            db_path='cell_thalamus_results.db'
        )

        print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                      âœ… COMPLETE!                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Design ID: {design_id}
Results: cell_thalamus_results.db
""")

        # Auto-upload to S3 (with merge to preserve previous experiments)
        try:
            import boto3
            import os
            S3_BUCKET = 'insitro-user'
            S3_KEY = 'brig/cell_thalamus_results.db'
            LOCAL_DB = 'cell_thalamus_results.db'

            print(f"\nðŸ“¤ Auto-uploading to S3...")
            s3 = boto3.client('s3')

            # Download existing S3 database to merge with it (if it exists)
            S3_TEMP = 'cell_thalamus_s3_existing.db'
            try:
                s3.download_file(S3_BUCKET, S3_KEY, S3_TEMP)
                print(f"   ðŸ“¥ Downloaded existing S3 database for merging...")

                # Merge our new results into the S3 database using Python sqlite3
                import sqlite3
                conn = sqlite3.connect(S3_TEMP)
                cursor = conn.cursor()

                # Attach the new local database
                cursor.execute(f"ATTACH DATABASE '{LOCAL_DB}' AS new_db")

                # Insert new designs and results (skip duplicates)
                cursor.execute("INSERT OR IGNORE INTO thalamus_designs SELECT * FROM new_db.thalamus_designs")
                cursor.execute("INSERT OR IGNORE INTO thalamus_results SELECT * FROM new_db.thalamus_results")

                # Commit and detach
                conn.commit()
                cursor.execute("DETACH DATABASE new_db")
                conn.close()

                print(f"   ðŸ”— Merged new results into existing database")

                # Upload the merged database
                s3.upload_file(S3_TEMP, S3_BUCKET, S3_KEY)
                os.remove(S3_TEMP)
            except s3.exceptions.NoSuchKey:
                # No existing S3 database, just upload ours
                print(f"   ðŸ“ No existing S3 database, creating new one...")
                s3.upload_file(LOCAL_DB, S3_BUCKET, S3_KEY)

            print(f"âœ… Uploaded to s3://{S3_BUCKET}/{S3_KEY}")
            print(f"\nðŸ”„ Your Mac will auto-download it within 30 seconds.")
            print(f"View at: http://localhost:5173/cell-thalamus")
        except ImportError:
            # boto3 not available - probably running locally
            print(f"\nðŸ’¡ Running locally (boto3 not available)")
            print(f"   Results saved to: cell_thalamus_results.db")
        except Exception as e:
            print(f"\nâš ï¸  S3 upload failed: {e}")
            print(f"   Manual upload: aws s3 cp cell_thalamus_results.db s3://insitro-user/brig/cell_thalamus_results.db")

        return design_id

    finally:
        # Restore original generate_design function
        standalone.generate_design = original_generate

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Run autonomous loop from JSON candidates')
    parser.add_argument('--candidates', required=True, help='Path to candidates JSON file')
    parser.add_argument('--workers', type=int, default=8, help='Number of parallel workers')

    args = parser.parse_args()

    run_autonomous_loop(args.candidates, workers=args.workers)
